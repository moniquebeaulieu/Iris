{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an Iris classifier, save to file\n",
    "\n",
    "Author: *Monique Beaulieu*\n",
    "\n",
    "Steps are:\n",
    "1. Load iris dataset from sklearn.\n",
    "2. use `train_test_split()` with `random_state=34` to create train and test sets.\n",
    "3. Train a logistic regression model on the training data.\n",
    "4. Print accuracy on the test dataset.\n",
    "5. Save the model to file using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5,\n",
    "                          return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_)) # best parameter for C is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: {}\".format(model.score(X_test, y_test))) # this makes me think its overfitting??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris-classifier.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'iris-classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-set score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# checking to see if this worked\n",
    "clf = load('iris-classifier.joblib')\n",
    "print(\"test-set score: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "1. Explain in words the sequence of actions (files and functions) to generate the predicted output. Start with a user visiting `http://localhost:5000`.\n",
    "2. List three ways to modify, improve or extend this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. \n",
    "- the trained model is loaded from joblib file \n",
    "- route ('/') calls the index function in the flask-ml-server.py and render_template of the html file \"prediction_input\" is returned (so displayed on server) \n",
    "- this prediction input template allows for the user to input values for the iris features\n",
    "- after inputing and clicking the \"Get prediciton\" button the server goes to the route '/iris_prediction'\n",
    "- once values are inputed there is a get method that calls the get_iris_prediction function in the flask-ml-server.py file\n",
    "- this get_iris_prediction function creates a 2D array of the inputed feature values\n",
    "- the .predict function is then applied to the loaded model with the array of the feature values from the user\n",
    "- the location (index value) for the target names array is returned from .predict\n",
    "- using the 2D array of the target names and the index value, the string of the predicted iris species is assigned to a variable pred_str\n",
    "- Similarly, the .predict_proba function is applied to the loaded model with the array of the feature values from the user\n",
    "- this creates a 2D array of the probabilities of each target\n",
    "- the location (index value) for the correct predicted probability can be found using the index value found in .predict, the float is assigned to a variable pred_proba\n",
    "- Finally, the render_template of the html file 'prediciton_response' is returned which includes the variables that include the predicted iris species pred_str and the predicted probability pred_proba which is displayed on the server\n",
    "- the flask server tells which html files to display when, and the .css file styles the page how you want it (font, background colour, etc.)\n",
    "\n",
    "2. \n",
    "- We could see if using a different model would be better. Scaling the data could also be a possibility. (however the test accuracy is already at 100% so im not sure this would count as improving)\n",
    "- we could use PCA and have another page where you only have to input the principal feature values and see how that compares\n",
    "- we could display an image of the predicted species\n",
    "- we could display the prediction probability of the other species, possibly there is a close call like ~50% so you would want to see what other species it could be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection \n",
    "Include a sentence or two about:\n",
    "\n",
    "what you liked or disliked,\n",
    "found interesting, confusing, challangeing, motivating while working on this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- I started off making this more complicated than it needed to be I started making a pipeline I thought we were supposed to figure out which classifier model to use etc. \n",
    "- I liked how he combined some of our old knowledge about flask stuff from last year. That was fun to refresh the memory\n",
    "- definitely wouldnt have been able to figure out the whole indexing thing without help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
